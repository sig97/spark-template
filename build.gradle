plugins {
    id 'java'
    id 'com.avast.gradle.docker-compose' version '0.9.3'
    id 'com.github.johnrengelman.shadow' version '5.1.0'
}

group 'com.nonradioactive.spark'
version '1.0-SNAPSHOT'

apply plugin: 'java'
apply plugin: 'scala'
apply plugin: 'idea'

sourceCompatibility = 1.8
targetCompatibility = 1.8

ext {
    lombokVersion = "1.18.8"
}

configurations {
    provided
}

sourceSets {
    main {
        compileClasspath += configurations.provided
        main.resources.srcDirs += '/data'
    }
}

repositories {
    jcenter()
    mavenLocal()
    mavenCentral()
    maven {
        url "https://oss.sonatype.org/content/repositories/snapshots"
    }
}

dependencies {
    implementation "com.fasterxml.jackson.module:jackson-module-scala_2.11:${jacksonVersion}"
    implementation "com.fasterxml.jackson.core:jackson-databind:${jacksonVersion}"
    implementation "com.fasterxml.jackson.core:jackson-core:${jacksonVersion}"

    implementation "org.scala-lang:scala-library:${scalaVersion}"
    implementation "org.scala-lang:scala-reflect:${scalaVersion}"
    implementation "org.scala-lang:scala-compiler:${scalaVersion}"

    implementation group: 'mysql', name: 'mysql-connector-java', version: '8.0.17'
    implementation group: 'org.elasticsearch', name: 'elasticsearch-spark-20_2.11', version: '7.3.1'
    testImplementation group: 'org.elasticsearch', name: 'elasticsearch-spark-20_2.11', version: '7.3.1'


    implementation "org.slf4j:slf4j-api:${slf4jVersion}"
    implementation "org.slf4j:slf4j-log4j12:${slf4jVersion}"

    implementation "org.apache.spark:spark-core_2.11:${sparkVersion}"
    implementation "org.apache.spark:spark-sql_2.11:${sparkVersion}"
    implementation "org.apache.spark:spark-mllib_2.11:${sparkVersion}"

    testImplementation "org.apache.spark:spark-core_2.11:${sparkVersion}"
    testImplementation "org.apache.spark:spark-sql_2.11:${sparkVersion}"
    testImplementation "org.apache.spark:spark-mllib_2.11:${sparkVersion}"

    testCompile "org.junit.jupiter:junit-jupiter-params:${junitVersion}"
    testImplementation "org.junit.jupiter:junit-jupiter-api:${junitVersion}"
    testRuntime "org.junit.jupiter:junit-jupiter-engine:${junitVersion}"

    testImplementation group: 'com.github.javafaker', name: 'javafaker', version: '1.0.1'

//    implementation "org.apache.spark:spark-streaming-flume-assembly_2.11:2.4.3"
//    implementation "org.apache.spark:spark-graphx_2.11:${sparkVersion}"
//    implementation "org.apache.spark:spark-launcher_2.11:${sparkVersion}"
//    implementation "org.apache.spark:spark-catalyst_2.11:${sparkVersion}"
//    implementation "org.apache.spark:spark-streaming_2.11:${sparkVersion}"
}

task run(type: JavaExec, dependsOn: classes) {
    main = mainClassFile
    classpath sourceSets.main.runtimeClasspath
    classpath configurations.runtime
}

test {
    useJUnitPlatform {
        excludeTags 'integration'
    }
    exclude '**/excluded/**'
    reports {
        html.enabled = true
    }
}

task integrationTest(type: Test) {
    description = 'Run integration tests.'
    group = 'verification'

    useJUnitPlatform {
        includeTags 'integration'
    }
    reports {
        html.enabled = true
    }
    testLogging.showStandardStreams = true

    testLogging {
        events 'PASSED', 'FAILED', 'SKIPPED'
    }
}

task dockerTest(dependsOn: integrationTest) {
    description = 'Launch external dependencies with docker-compose and run integration tests.'
    group = 'verification'
}

dockerCompose.isRequiredBy(dockerTest)

dockerCompose {
    useComposeFiles = ['docker-compose.yaml']
    startedServices = ['mysql']
    ignorePushFailure = true
    stopContainers = false
}

jar {
    archiveClassifier = 'all'
    manifest {
        attributes 'Implementation-Title': title,
                'Implementation-Version': version,
                'Main-Class': mainClassFile
    }
    include{sourceSets.main.output.classesDirs}
    zip64 true
}

shadowJar {
    archiveClassifier = 'shadow'
    append 'reference.conf'
    dependencies {
    }
}

idea {
    module {
        // IntelliJ does not know about the standard idiom of provided as used in managing
        // uber/shaded jar dependencies. Make it so!
        scopes.PROVIDED.plus += [ configurations.provided ]
    }
}
